{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[{"file_id":"1X8QbVoXyVAW-pfcE9_W5tdA6BJ6TiBoS","timestamp":1665583248928},{"file_id":"1rDdcBxXhqI3AZjCFdDaJxChaIUoFqeGn","timestamp":1663765914763},{"file_id":"13wk-uH95GeGB0W5MU7RHRDf1PE8fzEag","timestamp":1603810050900}],"collapsed_sections":["48x_ha7f8J5i","YRoiGbhvmSLO"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"PbzBJ1m9FBBb"},"source":["<center><h1>2-ab: Introduction to Neural Networks</h1></center>\n","\n","<center><h2><a href=\"https://rdfia.github.io/\">Course link</a></h2></center>\n","\n","# Warning : \n","# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved.\n"]},{"cell_type":"code","metadata":{"id":"NfnKy8NB8J5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668795407680,"user_tz":-60,"elapsed":1128,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}},"outputId":"37a8131e-e054-4f33-8ca9-9eb80b9edc11"},"source":["!wget https://github.com/rdfia/rdfia.github.io/raw/master/data/2-ab.zip\n","!unzip -j 2-ab.zip\n","!wget https://github.com/rdfia/rdfia.github.io/raw/master/code/2-ab/utils-data.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-18 18:16:45--  https://github.com/rdfia/rdfia.github.io/raw/master/data/2-ab.zip\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/data/2-ab.zip [following]\n","--2022-11-18 18:16:45--  https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/data/2-ab.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13423991 (13M) [application/zip]\n","Saving to: ‘2-ab.zip’\n","\n","2-ab.zip            100%[===================>]  12.80M  --.-KB/s    in 0.1s    \n","\n","2022-11-18 18:16:46 (121 MB/s) - ‘2-ab.zip’ saved [13423991/13423991]\n","\n","Archive:  2-ab.zip\n","  inflating: ._2-ab                  \n","  inflating: circles.mat             \n","  inflating: ._circles.mat           \n","  inflating: mnist.mat               \n","  inflating: ._mnist.mat             \n","  inflating: .DS_Store               \n","  inflating: ._.DS_Store             \n","--2022-11-18 18:16:46--  https://github.com/rdfia/rdfia.github.io/raw/master/code/2-ab/utils-data.py\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-ab/utils-data.py [following]\n","--2022-11-18 18:16:46--  https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-ab/utils-data.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3950 (3.9K) [text/plain]\n","Saving to: ‘utils-data.py’\n","\n","utils-data.py       100%[===================>]   3.86K  --.-KB/s    in 0s      \n","\n","2022-11-18 18:16:46 (50.2 MB/s) - ‘utils-data.py’ saved [3950/3950]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"2vQ_LLdx8J5b"},"source":["import math\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%run 'utils-data.py'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48x_ha7f8J5i"},"source":["# Part 1 : Forward and backward passes \"by hands\""]},{"cell_type":"code","metadata":{"id":"GtizX1JV8J5n"},"source":["def init_params(nx, nh, ny):\n","    \"\"\"\n","    nx, nh, ny: integers\n","    out params: dictionnary\n","    \"\"\"\n","    params = {}\n","    \n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wh, Wy, bh, by\n","    \n","    params[\"Wh\"] = 0.3*torch.randn(nh, nx)\n","    params[\"Wy\"] = 0.3*torch.randn(ny, nh)\n","    params[\"bh\"] = torch.zeros(1, nh)\n","    params[\"by\"] = torch.zeros(1, ny)\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk-N_Ny67yo-"},"source":["def forward(params, X):\n","    \"\"\"\n","    params: dictionnary\n","    X: (n_batch, dimension)\n","    \"\"\"\n","    bsize = X.size(0)\n","    nh = params['Wh'].size(0)\n","    ny = params['Wy'].size(0)\n","    outputs = {}\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for X, htilde, h, ytilde, yhat\n","    \n","    outputs[\"X\"] = X\n","    outputs[\"htilde\"] = X @ params['Wh'].T + params['bh']\n","    outputs[\"h\"] = torch.tanh(outputs[\"htilde\"])\n","    outputs[\"ytilde\"] = outputs[\"h\"] @ params['Wy'].T + params['by']\n","    outputs[\"yhat\"] = torch.softmax(outputs[\"ytilde\"], dim=1)\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return outputs['yhat'], outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uB0A2b28NZK"},"source":["def loss_accuracy(Yhat, Y):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    _, indsY = torch.max(Y, 1)\n","    _, indsYhat = torch.max(Yhat, 1)\n","    \n","    L = torch.mean(- torch.log(Yhat) * Y)\n","    acc = (indsY == indsYhat).float().mean()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return L, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWJjdiFe8qi5"},"source":["def backward(params, outputs, Y):\n","    bsize = Y.shape[0]\n","    grads = {}\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wy, Wh, by, bh\n","    grad_ytilde = (1 /bsize)*(outputs[\"yhat\"] - Y)\n","\n","    grads[\"Wy\"] = grad_ytilde.T @ outputs[\"h\"]    \n","    grads[\"Wh\"] = ((1 - outputs[\"h\"]**2) * (grad_ytilde @ params[\"Wy\"])).T @ outputs[\"X\"]\n","    grads[\"by\"] = (1 /(Y.size(0))*(outputs[\"yhat\"] - Y)).sum(dim=0).T\n","    grads[\"bh\"] = ((1 /(Y.size(0))*(outputs[\"yhat\"] - Y)) @ params[\"Wy\"] * (1 - outputs[\"h\"]**2)).sum(dim=0).T\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","    return grads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAnsISsW9CnH"},"source":["def sgd(params, grads, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the params values\n","\n","    params[\"Wh\"] = params[\"Wh\"] - eta * grads[\"Wh\"]\n","    params[\"Wy\"] = params[\"Wy\"] - eta * grads[\"Wy\"]\n","    params[\"bh\"] = params[\"bh\"] - eta * grads[\"bh\"]\n","    params[\"by\"] = params[\"by\"] - eta * grads[\"by\"]    \n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hifuW5UFA3DZ"},"source":["## Global learning procedure \"by hands\""]},{"cell_type":"code","metadata":{"id":"4RSw6bd0-qUe","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17G7tCPMJg2BgjzzcL46L23hOtvToMNl4"},"outputId":"c2a5c94a-2118-45ac-ff2c-12620bcd1a63","executionInfo":{"status":"ok","timestamp":1668795464425,"user_tz":-60,"elapsed":53394,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}}},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 15\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.05\n","\n","params = init_params(nx, nh, ny)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(200):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","\n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: forward, loss_accuracy, backward, sgd\n","        Yhat, out = forward(params, X)\n","        Ltrain, acctrain = loss_accuracy(Yhat, Y)\n","        grads = backward(params, out, Y)\n","        params = sgd(params, grads, eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","\n","    Yhat_train, _ = forward(params, data.Xtrain)\n","    Yhat_test, _ = forward(params, data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n","    Ygrid, _ = forward(params, data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title)\n","    data.plot_data_with_grid(Ygrid, title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain)\n","    curves[3].append(Ltest)\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"OrHHH5PL8J54"},"source":["# Part 2 : Simplification of the backward pass with `torch.autograd`\n","\n"]},{"cell_type":"code","metadata":{"id":"7G4q5zP0CEvB"},"source":["def init_params(nx, nh, ny):\n","    \"\"\"\n","    nx, nh, ny: integers\n","    out params: dictionnary\n","    \"\"\"\n","    params = {}\n","    \n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # fill values for Wh, Wy, bh, by\n","    \n","    params[\"Wh\"] = torch.randn(nh, nx)*0.3\n","    params[\"Wh\"].requires_grad = True\n","    params[\"Wy\"] = torch.randn(ny, nh)\n","    params[\"Wy\"].requires_grad = True\n","    params[\"bh\"] = torch.zeros(1, nh, requires_grad=True)\n","    params[\"by\"] = torch.zeros(1, ny, requires_grad=True)\n","    \n","    ####################\n","    ##      END        #\n","    ####################\n","    return params\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL0tSjpKCyVB"},"source":["The function `forward` remains unchanged from previous part. \n","\n","The function `backward` is no longer used because of \"autograd\". "]},{"cell_type":"code","metadata":{"id":"hA4ycHlfBzCK"},"source":["def sgd(params, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the network weights\n","    # warning: use torch.no_grad()\n","    # and reset to zero the gradient accumulators\n","    \n","    with torch.no_grad():\n","      params[\"Wh\"] -= eta * params[\"Wh\"].grad\n","      params[\"Wy\"] -= eta * params[\"Wy\"].grad\n","      params[\"bh\"] -= eta * params[\"bh\"].grad\n","      params[\"by\"] -= eta * params[\"by\"].grad\n","      \n","      params[\"Wh\"].grad.zero_()\n","      params[\"Wy\"].grad.zero_()\n","      params[\"bh\"].grad.zero_()\n","      params[\"by\"].grad.zero_()\n","    ####################\n","    ##      END        #\n","    ####################\n","    return params"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rjgcmgQpDfOb"},"source":["## Global learning procedure with autograd"]},{"cell_type":"code","metadata":{"id":"8p5oR3EqDea-","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TFmWLWTO_x0zUNW00R_dHlGj8svL8Ci7"},"executionInfo":{"status":"ok","timestamp":1668795513487,"user_tz":-60,"elapsed":49079,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}},"outputId":"d049945d-509d-46af-baac-54949fa75d28"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","params = init_params(nx, nh, ny)\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(200):\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: forward, loss_accuracy, sgd\n","        # and the backward function with autograd\n","        Yhat, out = forward(params, X)\n","        Ltrain, _ = loss_accuracy(Yhat, Y)\n","        Ltrain.backward()\n","        params = sgd(params, eta)\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","\n","    Yhat_train, _ = forward(params, data.Xtrain)\n","    Yhat_test, _ = forward(params, data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n","    Ygrid, _ = forward(params, data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title)\n","    # detach() is used to remove the predictions from the computational graph in autograd\n","    data.plot_data_with_grid(Ygrid.detach(), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain.item())\n","    curves[3].append(Ltest.item())\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5FV1iss68J6H"},"source":["# Part 3 : Simplification of the forward pass with `torch.nn`"]},{"cell_type":"markdown","metadata":{"id":"x6T5Uq7JEl47"},"source":["`init_params` and `forward` are replaced by the `init_model` function which defines the network architecture and the loss."]},{"cell_type":"code","metadata":{"id":"5-h4r-FH8J6I"},"source":["def init_model(nx, nh, ny):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    model = torch.nn.Sequential(\n","      torch.nn.Linear(nx, nh),\n","      torch.nn.Tanh(),\n","      torch.nn.Linear(nh, ny)\n","    )\n","    loss = torch.nn.CrossEntropyLoss()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return model, loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geE_TI96FXnl"},"source":["def loss_accuracy(loss, Yhat, Y):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # call the loss function\n","\n","    _, indsY = torch.max(Y, 1)\n","    _, indsYhat = torch.max(nn.functional.softmax(Yhat, dim=1), 1)\n","    \n","    L = loss(Yhat, Y)\n","    acc = (indsY == indsYhat).float().mean()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return L, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e93bvFiYGKnA"},"source":["def sgd(model, eta):\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # update the network weights\n","    # warning: use torch.no_grad()\n","    # and reset to zero the gradient accumulators\n","    with torch.no_grad():\n","      for param in model.parameters():\n","        param -= eta * param.grad\n","      model.zero_grad()\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aOxBMmD4Gxtp"},"source":["## Global learning procedure with autograd and `torch.nn`"]},{"cell_type":"code","metadata":{"id":"4hMBmCNvHCLn","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HAwX-XDfiyY4i6km0NQ3_Sh6s5BQHIY_"},"executionInfo":{"status":"ok","timestamp":1668795555522,"user_tz":-60,"elapsed":42042,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}},"outputId":"1da3e43d-7125-4565-b7bd-98b35c910d79"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 10\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","model, loss = init_model(nx, nh, ny)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","\n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy, sgd\n","        # the forward with the predict method from the model\n","        # and the backward function with autograd\n","        Yhats = model(X)\n","        Ltrain, _ = loss_accuracy(loss, Yhats, Y)\n","        Ltrain.backward()\n","        model = sgd(model, eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","    Ygrid = model(data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title) \n","    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain.item())\n","    curves[3].append(Ltest.item())\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"GoFSrQNsJCnz"},"source":["# Part 4 : Simplification of the SGD with `torch.optim`"]},{"cell_type":"code","metadata":{"id":"S8WtN9loJPqP"},"source":["def init_model(nx, nh, ny, eta):\n","\n","    #####################\n","    ## Your code here  ##\n","    #####################\n","\n","    model = torch.nn.Sequential(\n","      torch.nn.Linear(nx, nh),\n","      torch.nn.Tanh(),\n","      torch.nn.Linear(nh, ny)\n","    )\n","    loss = torch.nn.CrossEntropyLoss()\n","    optim = torch.optim.SGD(model.parameters(), lr=eta)\n","\n","    ####################\n","    ##      END        #\n","    ####################\n","\n","    return model, loss, optim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eY-0rRzPJYDd"},"source":["The `sgd` function is replaced by calling the `optim.zero_grad()` before the backward and `optim.step()` after. "]},{"cell_type":"markdown","metadata":{"id":"q82hCupvJxvV"},"source":["## Algorithme global d'apprentissage (avec autograd, les couches `torch.nn` et `torch.optim`)"]},{"cell_type":"code","metadata":{"id":"V9h9nINKJ1LU","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vIVUDe2RrKQB0ovTyv3Yus1WXPGGFq46"},"executionInfo":{"status":"ok","timestamp":1668799498173,"user_tz":-60,"elapsed":36750,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}},"outputId":"7e5c9ab4-6df7-4e40-bac2-ba3cedf4cbcb"},"source":["# init\n","data = CirclesData()\n","data.plot_data()\n","N = data.Xtrain.shape[0]\n","Nbatch = 5\n","nx = data.Xtrain.shape[1]\n","nh = 10\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","model, loss, optim = init_model(nx, nh, ny, eta)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code  here ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy\n","        # the forward with the predict method from the model\n","        # the backward function with autograd\n","        # and then an optimization step\n","        Yhats = model(X)\n","        Ltrain, _ = loss_accuracy(loss, Yhats, Y)\n","        \n","        optim.zero_grad()\n","        Ltrain.backward()\n","        optim.step()\n","\n","    ####################\n","    ##      FIN        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","    Ygrid = model(data.Xgrid)  \n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","    print(title) \n","    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain.item())\n","    curves[3].append(Ltest.item())\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Ts1s4JuOSaZ3"},"source":["# Part 5 : MNIST"]},{"cell_type":"markdown","metadata":{"id":"jly9C4FCSzLP"},"source":["Apply the code from previous part code to the MNIST dataset."]},{"cell_type":"code","metadata":{"id":"osrFoEr_Syi7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668795864388,"user_tz":-60,"elapsed":273142,"user":{"displayName":"Antoine Siraudin","userId":"13320365833125800896"}},"outputId":"6e5b1c4f-3e46-4bdd-b922-89e1ed0893fd"},"source":["# init\n","data = MNISTData()\n","N = data.Xtrain.shape[0]\n","Nbatch = 100\n","nx = data.Xtrain.shape[1]\n","nh = 100\n","ny = data.Ytrain.shape[1]\n","eta = 0.03\n","\n","model, loss, optim = init_model(nx, nh, ny, eta)\n","\n","curves = [[],[], [], []]\n","\n","# epoch\n","for iteration in range(150):\n","    # permute\n","    perm = np.random.permutation(N)\n","    Xtrain = data.Xtrain[perm, :]\n","    Ytrain = data.Ytrain[perm, :]\n","\n","    #####################\n","    ## Your code  here ##\n","    #####################\n","    # batches\n","    for j in range(N // Nbatch):\n","\n","        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n","        X = Xtrain[indsBatch, :]\n","        Y = Ytrain[indsBatch, :]\n","  \n","        # write the optimization algorithm on the batch (X,Y)\n","        # using the functions: loss_accuracy\n","        # the forward with the predict method from the model\n","        # the backward function with autograd\n","        # and then an optimization step\n","        Yhats = model(X)\n","        Ltrain, _ = loss_accuracy(loss, Yhats, Y)\n","        \n","        optim.zero_grad()\n","        Ltrain.backward()\n","        optim.step()\n","\n","    ####################\n","    ##      FIN        #\n","    ####################\n","\n","\n","    Yhat_train = model(data.Xtrain)\n","    Yhat_test = model(data.Xtest)\n","    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n","    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n","\n","    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n","\n","    curves[0].append(acctrain)\n","    curves[1].append(acctest)\n","    curves[2].append(Ltrain.item())\n","    curves[3].append(Ltest.item())\n","\n","fig = plt.figure()\n","plt.plot(curves[0], label=\"acc. train\")\n","plt.plot(curves[1], label=\"acc. test\")\n","plt.plot(curves[2], label=\"loss train\")\n","plt.plot(curves[3], label=\"loss test\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YRoiGbhvmSLO"},"source":["# Part 6: Bonus: SVM\n","\n","\n","Train a SVM model on the Circles dataset.\n","\n","Ideas : \n","- First try a linear SVM (sklearn.svm.LinearSVC dans scikit-learn). Does it work well ? Why ?\n","- Then try more complex kernels (sklearn.svm.SVC). Which one is the best ? why ?\n","- Does the parameter C of regularization have an impact? Why ?"]},{"cell_type":"code","metadata":{"id":"VWeW8siymR3g"},"source":["# data\n","data = CirclesData()\n","Xtrain = data.Xtrain.numpy()\n","Ytrain = data.Ytrain[:, 0].numpy()\n","\n","Xgrid = data.Xgrid.numpy()\n","\n","Xtest = data.Xtest.numpy()\n","Ytest = data.Ytest[:, 0].numpy()\n","\n","def plot_svm_predictions(data, predictions):\n","      plt.figure(2)\n","      plt.clf()\n","      plt.imshow(np.reshape(predictions, (40,40)))\n","      plt.plot(data._Xtrain[data._Ytrain[:,0] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,0] == 1,1]*10+20, 'bo', label=\"Train\")\n","      plt.plot(data._Xtrain[data._Ytrain[:,1] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,1] == 1,1]*10+20, 'ro')\n","      plt.plot(data._Xtest[data._Ytest[:,0] == 1,0]*10+20, data._Xtest[data._Ytest[:,0] == 1,1]*10+20, 'b+', label=\"Test\")\n","      plt.plot(data._Xtest[data._Ytest[:,1] == 1,0]*10+20, data._Xtest[data._Ytest[:,1] == 1,1]*10+20, 'r+')\n","      plt.xlim(0,39)\n","      plt.ylim(0,39)\n","      plt.clim(0.3,0.7)\n","      plt.draw()\n","      plt.pause(1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1xcE6zbmXU1"},"source":["import sklearn.svm\n","\n","############################\n","### Your code here   #######\n","### Train the SVM    #######\n","## See https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n","## and https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","############################\n","\n","svm = None\n","\n","###########################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgLl7B_3mbOs"},"source":["## Print results\n","\n","Ytest_pred = svm.predict(Xtest)\n","accuracy = np.sum(Ytest == Ytest_pred) / len(Ytest)\n","print(f\"Accuracy : {100 * accuracy:.2f}\")\n","Ygrid_pred = svm.predict(Xgrid)\n","plot_svm_predictions(data, Ygrid_pred)"],"execution_count":null,"outputs":[]}]}